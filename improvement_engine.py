#!/usr/bin/env python3
"""
Improvement Engine - è‡ªå·±æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³

è©•ä¾¡çµæœã‹ã‚‰å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã€è‡ªå‹•çš„ã«æ”¹å–„ã‚’é©ç”¨ã™ã‚‹ã€‚
"""

import os
import json
import logging
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
import hashlib

try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent / '.env')
except ImportError:
    pass

try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False


class ImprovementEngine:
    """è‡ªå‹•æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, supabase: Client, logger: Optional[logging.Logger] = None):
        self.supabase = supabase
        self.logger = logger or self._setup_logging()
        self.projects_dir = Path.home() / 'projects'

        # å®‰å…¨æ€§è¨­å®š
        self.cooldown_hours = 24  # åŒã˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯24æ™‚é–“ã«1å›ã¾ã§
        self.max_improvements_per_week = 3  # åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯é€±ã«3å›ã¾ã§

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
        logger = logging.getLogger('ImprovementEngine')
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        logger.addHandler(handler)
        return logger

    def get_project_config(self, project_id: str) -> dict:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’DBã‹ã‚‰å–å¾—

        Returns:
            {
                'directory': str,  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
                'session_name': str,  # Resume ã‚»ãƒƒã‚·ãƒ§ãƒ³å
                'repo_url': str  # ãƒªãƒã‚¸ãƒˆãƒªURL
            }
        """
        try:
            result = self.supabase.table('orch_projects').select(
                'local_directory, resume_session_name, repository_url'
            ).eq('id', project_id).single().execute()

            if result.data:
                return {
                    'directory': result.data.get('local_directory') or project_id,
                    'session_name': result.data.get('resume_session_name') or f"orch-{project_id}",
                    'repo_url': result.data.get('repository_url')
                }
        except Exception as e:
            self.logger.warning(f"Failed to get project config from DB: {e}. Using defaults.")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'directory': project_id,
            'session_name': f"orch-{project_id}",
            'repo_url': None
        }

    def check_triggers(self, project_id: str) -> Optional[Dict[str, Any]]:
        """
        æ”¹å–„ãƒˆãƒªã‚¬ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            ãƒˆãƒªã‚¬ãƒ¼æƒ…å ±ï¼ˆæ¤œå‡ºã•ã‚Œãªã‘ã‚Œã°Noneï¼‰
            {
                'trigger_type': 'consecutive_failures' or 'low_score',
                'details': {...}
            }
        """
        # ãƒˆãƒªã‚¬ãƒ¼1: åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ãŒ3å›é€£ç¶š
        consecutive_failure_trigger = self._check_consecutive_failures(project_id)
        if consecutive_failure_trigger:
            return consecutive_failure_trigger

        # ãƒˆãƒªã‚¬ãƒ¼2: ç›´è¿‘5å®Ÿè¡Œã®å¹³å‡ã‚¹ã‚³ã‚¢ãŒ5.0æœªæº€
        low_score_trigger = self._check_low_average_score(project_id)
        if low_score_trigger:
            return low_score_trigger

        return None

    def _check_consecutive_failures(self, project_id: str) -> Optional[Dict[str, Any]]:
        """3å›é€£ç¶šã®åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ã‚’æ¤œå‡º"""
        try:
            # ç›´è¿‘10å®Ÿè¡Œã‚’å–å¾—
            response = self.supabase.table('orch_runs') \
                .select('id, status, created_at') \
                .eq('project_id', project_id) \
                .order('created_at', desc=True) \
                .limit(10) \
                .execute()

            runs = response.data or []
            if len(runs) < 3:
                return None

            # ç›´è¿‘3ã¤ãŒå¤±æ•—ã‹ãƒã‚§ãƒƒã‚¯
            recent_runs = runs[:3]
            if not all(run['status'] == 'failed' for run in recent_runs):
                return None

            # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¤±æ•—ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
            run_ids = [run['id'] for run in recent_runs]
            eval_response = self.supabase.table('orch_evaluations') \
                .select('run_id, failure_category') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = eval_response.data or []
            if len(evaluations) < 3:
                return None

            # åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ãŒ3å›ç¶šã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            categories = [e['failure_category'] for e in evaluations if e['failure_category']]
            if len(categories) >= 3 and categories[0] == categories[1] == categories[2]:
                return {
                    'trigger_type': 'consecutive_failures',
                    'details': {
                        'failure_category': categories[0],
                        'run_ids': run_ids,
                        'count': 3
                    }
                }

            return None

        except Exception as e:
            self.logger.error(f"Error checking consecutive failures: {e}")
            return None

    def _check_low_average_score(self, project_id: str) -> Optional[Dict[str, Any]]:
        """ç›´è¿‘5å®Ÿè¡Œã®å¹³å‡ã‚¹ã‚³ã‚¢ãŒ5.0æœªæº€ã‚’æ¤œå‡º"""
        try:
            # ç›´è¿‘5å®Ÿè¡Œã®è©•ä¾¡ã‚’å–å¾—
            response = self.supabase.table('orch_runs') \
                .select('id') \
                .eq('project_id', project_id) \
                .order('created_at', desc=True) \
                .limit(5) \
                .execute()

            runs = response.data or []
            if len(runs) < 5:
                return None

            run_ids = [run['id'] for run in runs]
            eval_response = self.supabase.table('orch_evaluations') \
                .select('overall_score') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = eval_response.data or []
            if len(evaluations) < 5:
                return None

            scores = [e['overall_score'] for e in evaluations]
            avg_score = sum(scores) / len(scores)

            if avg_score < 5.0:
                return {
                    'trigger_type': 'low_score',
                    'details': {
                        'average_score': avg_score,
                        'run_ids': run_ids,
                        'scores': scores
                    }
                }

            return None

        except Exception as e:
            self.logger.error(f"Error checking low average score: {e}")
            return None

    def check_cooldown(self, project_id: str) -> bool:
        """
        ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            True: æ”¹å–„å¯èƒ½, False: ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­
        """
        try:
            # ç›´è¿‘ã®æ”¹å–„å±¥æ­´ã‚’å–å¾—
            cutoff_time = (datetime.now() - timedelta(hours=self.cooldown_hours)).isoformat()

            response = self.supabase.table('orch_improvement_history') \
                .select('applied_at') \
                .eq('project_id', project_id) \
                .gte('applied_at', cutoff_time) \
                .execute()

            if response.data and len(response.data) > 0:
                self.logger.info(f"Project {project_id} is in cooldown period")
                return False

            return True

        except Exception as e:
            self.logger.error(f"Error checking cooldown: {e}")
            return False

    def aggregate_improvements(self, run_ids: List[int]) -> Dict[str, Any]:
        """
        è©•ä¾¡ã‹ã‚‰æ”¹å–„ææ¡ˆã‚’é›†ç´„ï¼ˆã‚¹ã‚­ãƒ«ãƒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã‚’å«ã‚€ï¼‰

        Args:
            run_ids: å¯¾è±¡ã®run IDãƒªã‚¹ãƒˆ

        Returns:
            æ”¹å–„ææ¡ˆã®è¾æ›¸ï¼ˆsuggestions, ineffective_skills, missing_skills, agent_suggestionsï¼‰
        """
        try:
            response = self.supabase.table('orch_evaluations') \
                .select('improvement_suggestions, tool_usage_analysis') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = response.data or []
            all_suggestions = []
            ineffective_skills = []
            missing_skills = []
            agent_suggestions = []

            for evaluation in evaluations:
                try:
                    # ä¸€èˆ¬çš„ãªæ”¹å–„ææ¡ˆ
                    suggestions = json.loads(evaluation['improvement_suggestions'])
                    all_suggestions.extend(suggestions)

                    # ã‚¹ã‚­ãƒ«ãƒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡
                    tool_usage = json.loads(evaluation.get('tool_usage_analysis', '{}'))
                    skill_eff = tool_usage.get('skill_effectiveness', {})
                    agent_eff = tool_usage.get('agent_effectiveness', {})

                    # åŠ¹æœã®ãªã„ã‚¹ã‚­ãƒ«
                    if skill_eff.get('ineffective_skills'):
                        ineffective_skills.extend(skill_eff['ineffective_skills'])

                    # ä¸è¶³ã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ«
                    if skill_eff.get('missing_skills'):
                        missing_skills.extend(skill_eff['missing_skills'])

                    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ”¹å–„ææ¡ˆ
                    if agent_eff.get('better_agent_suggestion'):
                        agent_suggestions.append(agent_eff['better_agent_suggestion'])

                except (json.JSONDecodeError, TypeError):
                    continue

            return {
                'suggestions': list(set(all_suggestions)),
                'ineffective_skills': list(set(ineffective_skills)),
                'missing_skills': list(set(missing_skills)),
                'agent_suggestions': list(set(agent_suggestions))
            }

        except Exception as e:
            self.logger.error(f"Error aggregating improvements: {e}")
            return {
                'suggestions': [],
                'ineffective_skills': [],
                'missing_skills': [],
                'agent_suggestions': []
            }

    def apply_improvement(self, project_id: str, trigger: Dict[str, Any], improvements: Dict[str, Any]) -> bool:
        """
        æ”¹å–„ã‚’é©ç”¨ï¼ˆåˆ¥ãƒ–ãƒ©ãƒ³ãƒã«ï¼‰

        Args:
            project_id: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            trigger: ãƒˆãƒªã‚¬ãƒ¼æƒ…å ±
            improvements: æ”¹å–„ææ¡ˆè¾æ›¸ï¼ˆsuggestions, ineffective_skills, missing_skills, agent_suggestionsï¼‰

        Returns:
            æˆåŠŸã—ãŸã‚‰True
        """
        try:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’DBã‹ã‚‰å–å¾—
            config = self.get_project_config(project_id)
            project_dir = self.projects_dir / config['directory']

            if not project_dir.exists():
                self.logger.error(f"Project directory not found: {project_dir}")
                return False

            # ãƒ–ãƒ©ãƒ³ãƒåã‚’ç”Ÿæˆ
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            branch_name = f"auto-improvement-{timestamp}"

            # æ”¹å–„å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            suggestions = improvements.get('suggestions', [])
            ineffective_skills = improvements.get('ineffective_skills', [])
            missing_skills = improvements.get('missing_skills', [])
            agent_suggestions = improvements.get('agent_suggestions', [])

            improvement_prompt = f"""## è‡ªå‹•æ”¹å–„ã‚¿ã‚¹ã‚¯ - ã‚¹ã‚­ãƒ«/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}

## ãƒˆãƒªã‚¬ãƒ¼
ã‚¿ã‚¤ãƒ—: {trigger['trigger_type']}
è©³ç´°: {json.dumps(trigger['details'], indent=2)}

## æ”¹å–„ææ¡ˆ
{chr(10).join(f'{i+1}. {s}' for i, s in enumerate(suggestions)) if suggestions else 'ï¼ˆä¸€èˆ¬çš„ãªæ”¹å–„ææ¡ˆãªã—ï¼‰'}

## ã‚¹ã‚­ãƒ«è©•ä¾¡çµæœ
### åŠ¹æœã®ãªã„ã‚¹ã‚­ãƒ«ï¼ˆå‰Šé™¤ã‚’æ¤œè¨ï¼‰:
{chr(10).join(f'  - {s}' for s in ineffective_skills) if ineffective_skills else '  ï¼ˆãªã—ï¼‰'}

### ä¸è¶³ã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ«ï¼ˆä½œæˆã‚’æ¨å¥¨ï¼‰:
{chr(10).join(f'  - {s}' for s in missing_skills) if missing_skills else '  ï¼ˆãªã—ï¼‰'}

## ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ”¹å–„ææ¡ˆ:
{chr(10).join(f'  - {s}' for s in agent_suggestions) if agent_suggestions else '  ï¼ˆãªã—ï¼‰'}

## æŒ‡ç¤º

ä¸Šè¨˜ã®å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ”¹å–„ææ¡ˆã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

### 1. ã‚¹ã‚­ãƒ«ç®¡ç†ï¼ˆæœ€å„ªå…ˆï¼‰
- `.claude/skills/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªãƒ»ä½œæˆ
- **åŠ¹æœã®ãªã„ã‚¹ã‚­ãƒ«ã‚’å‰Šé™¤**:
{chr(10).join(f'  * {s} ã‚’å‰Šé™¤ã¾ãŸã¯å¤§å¹…æ”¹ä¿®' for s in ineffective_skills) if ineffective_skills else '  ï¼ˆå‰Šé™¤å¯¾è±¡ãªã—ï¼‰'}
- **ä¸è¶³ã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ«ã‚’ä½œæˆ**:
{chr(10).join(f'  * {s} ã‚’ä½œæˆ' for s in missing_skills) if missing_skills else '  ï¼ˆä½œæˆä¸è¦ï¼‰'}
- ã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡: `{project_id}-[purpose].sh` ã¾ãŸã¯ `.py`
- ã‚¹ã‚­ãƒ«å†…å®¹: å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰/ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¿…é ˆ

### 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
- `.claude/agents/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªãƒ»ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’ä½œæˆ
  * ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
  * ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ãƒãƒªã‚·ãƒ¼
  * å¤±æ•—ã‚’é¿ã‘ã‚‹ãŸã‚ã®ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«

### 3. ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹æˆ
- ã‚¿ã‚¹ã‚¯ãŒè¤‡é›‘ãªå ´åˆã€ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµ„ã¿ç«‹ã¦æˆ¦ç•¥ã‚’ `.claude/subagents.md` ã«è¨˜éŒ²
- ã©ã®ã‚¿ã‚¹ã‚¯ã‚’ã©ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åˆ†å‰²ã™ã¹ãã‹ã®åˆ¤æ–­åŸºæº–

### 4. å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹æ´»ç”¨
- é¡ä¼¼ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹å…¬é–‹ã‚¹ã‚­ãƒ«/ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦æœ‰ç”¨ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„ãƒ„ãƒ¼ãƒ«ã‚’ `.claude/tools/` ã«é…ç½®

### 5. CLAUDE.mdæ›´æ–°
- ä»Šå›ã®å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–ã‚’è¨˜éŒ²
- ã‚¹ã‚­ãƒ«/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹æˆã®å¤‰æ›´ã‚’æ–‡æ›¸åŒ–
- ã€Œå¤±æ•—ã‹ã‚‰å­¦ã‚“ã ã“ã¨ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 

### 6. ã‚³ãƒ¼ãƒ‰æ”¹å–„ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- æ ¹æœ¬çš„ãªã‚³ãƒ¼ãƒ‰å•é¡ŒãŒã‚ã‚Œã°ä¿®æ­£
- ãŸã ã—ã‚¹ã‚­ãƒ«/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–ã‚’å„ªå…ˆ

## é‡è¦ãªæ³¨æ„äº‹é …
- æ—¢å­˜ã®æ©Ÿèƒ½ã‚’å£Šã•ãªã„ã“ã¨
- ã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯å®Ÿè¡Œå¯èƒ½ã§ã€æ˜ç¢ºãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å«ã‚€ã“ã¨
- å¤‰æ›´ã¯æ®µéšçš„ã«ï¼ˆä¸€åº¦ã«å¤šãã‚’å¤‰ãˆã™ããªã„ï¼‰
- ãƒ†ã‚¹ãƒˆå¯èƒ½ãªå½¢ã§å®Ÿè£…ã™ã‚‹ã“ã¨

## å‡ºåŠ›å½¢å¼

```changes
.claude/skills/[æ–°è¦ã‚¹ã‚­ãƒ«].sh - [ç›®çš„ã¨æ©Ÿèƒ½ã®èª¬æ˜]
.claude/agents/[è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«] - [ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã®èª¬æ˜]
CLAUDE.md - [å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–ã‚’è¿½è¨˜]
[ãã®ä»–ã®å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«] - [èª¬æ˜]
```

```skills-created
ã‚¹ã‚­ãƒ«å: [åå‰]
ç›®çš„: [ã“ã®ã‚¹ã‚­ãƒ«ãŒè§£æ±ºã™ã‚‹å•é¡Œ]
ä½¿ã„æ–¹: [å®Ÿè¡Œæ–¹æ³•]
---
ã‚¹ã‚­ãƒ«å: [åå‰]
...
```
"""

            self.logger.info(f"Applying improvement to {project_id} on branch {branch_name}")

            # Gitã§æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
            subprocess.run(
                ['git', 'checkout', '-b', branch_name],
                cwd=project_dir,
                check=True,
                capture_output=True
            )

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãå‡ºã™
            temp_file = Path('/tmp') / f'improvement_{project_id}_{timestamp}.txt'
            temp_file.write_text(improvement_prompt, encoding='utf-8')

            # Claude Codeã§æ”¹å–„ã‚’å®Ÿè¡Œ
            result = subprocess.run(
                ['bash', '-c', f'cd {project_dir} && cat {temp_file} | claude --dangerously-skip-permissions --print'],
                capture_output=True,
                text=True,
                timeout=600
            )

            temp_file.unlink(missing_ok=True)

            if result.returncode != 0:
                self.logger.error(f"Improvement execution failed: {result.stderr}")
                # ãƒ–ãƒ©ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦å…ƒã«æˆ»ã™
                subprocess.run(['git', 'checkout', '-'], cwd=project_dir, capture_output=True)
                subprocess.run(['git', 'branch', '-D', branch_name], cwd=project_dir, capture_output=True)
                return False

            # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
            subprocess.run(['git', 'add', '.'], cwd=project_dir, check=True)
            commit_message = f"""Auto-improvement: {trigger['trigger_type']}

Trigger details: {json.dumps(trigger['details'])}

Improvements applied:
{chr(10).join(f'- {s}' for s in suggestions[:5])}

ğŸ¤– Auto-generated improvement
"""
            subprocess.run(
                ['git', 'commit', '-m', commit_message],
                cwd=project_dir,
                check=True,
                capture_output=True
            )

            # æ”¹å–„å±¥æ­´ã‚’è¨˜éŒ²
            self._record_improvement_history(project_id, trigger, branch_name, result.stdout)

            self.logger.info(f"Improvement applied successfully to branch: {branch_name}")
            self.logger.info(f"Review and merge manually: cd {project_dir} && git checkout {branch_name}")

            return True

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Git operation failed: {e}")
            return False
        except subprocess.TimeoutExpired:
            self.logger.error("Improvement execution timed out")
            return False
        except Exception as e:
            self.logger.error(f"Error applying improvement: {e}")
            return False

    def _record_improvement_history(self, project_id: str, trigger: Dict[str, Any], branch_name: str, output: str):
        """æ”¹å–„å±¥æ­´ã‚’è¨˜éŒ²"""
        try:
            import re

            # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º
            changes_match = re.search(r'```changes\s*\n(.*?)\n```', output, re.DOTALL)
            changes_summary = changes_match.group(1) if changes_match else "No summary provided"

            # target_filesã‚’æ§‹ç¯‰
            target_files = []
            if changes_match:
                for line in changes_match.group(1).split('\n'):
                    if ':' in line:
                        file_path = line.split(':')[0].strip()
                        target_files.append(file_path)

            # ä½œæˆã•ã‚ŒãŸã‚¹ã‚­ãƒ«ã‚’æŠ½å‡º
            skills_match = re.search(r'```skills-created\s*\n(.*?)\n```', output, re.DOTALL)
            skills_created = []
            if skills_match:
                skill_blocks = skills_match.group(1).split('---')
                for block in skill_blocks:
                    if 'ã‚¹ã‚­ãƒ«å:' in block:
                        skills_created.append(block.strip())

            # orch_improvement_historyã«ä¿å­˜
            self.supabase.table('orch_improvement_history').insert({
                'project_id': project_id,
                'trigger_type': trigger['trigger_type'],
                'trigger_details': json.dumps(trigger['details']),
                'target_files': json.dumps(target_files),
                'changes_summary': changes_summary + (f"\n\n## Created Skills:\n{chr(10).join(skills_created)}" if skills_created else ""),
                'before_avg_score': trigger['details'].get('average_score', 0.0)
            }).execute()

            # ä½œæˆã•ã‚ŒãŸã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’orch_knowledge_assetsã«è¨˜éŒ²
            self._record_knowledge_assets(project_id, target_files, branch_name)

            self.logger.info(f"Improvement history recorded for {project_id}")
            if skills_created:
                self.logger.info(f"Created {len(skills_created)} new skills")

        except Exception as e:
            self.logger.error(f"Error recording improvement history: {e}")

    def _record_knowledge_assets(self, project_id: str, target_files: List[str], branch_name: str):
        """ä½œæˆã•ã‚ŒãŸã‚¹ã‚­ãƒ«/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’orch_knowledge_assetsã«è¨˜éŒ²"""
        try:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’DBã‹ã‚‰å–å¾—
            config = self.get_project_config(project_id)
            project_dir = self.projects_dir / config['directory']

            for file_path in target_files:
                # .claude/é…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¨˜éŒ²
                if not file_path.startswith('.claude/'):
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
                if '/skills/' in file_path:
                    asset_type = 'skill'
                elif '/agents/' in file_path:
                    asset_type = 'agent'
                elif 'subagents.md' in file_path:
                    asset_type = 'subagent_config'
                else:
                    asset_type = 'other'

                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
                full_path = project_dir / file_path
                if not full_path.exists():
                    continue

                try:
                    content = full_path.read_text(encoding='utf-8')
                    content_hash = hashlib.sha256(content.encode()).hexdigest()

                    # orch_knowledge_assetsã«ä¿å­˜
                    self.supabase.table('orch_knowledge_assets').insert({
                        'project_id': project_id,
                        'asset_type': asset_type,
                        'file_path': file_path,
                        'content': content,
                        'content_hash': content_hash,
                        'version': 1,
                        'auto_generated': True,
                        'created_by': 'improvement_engine'
                    }).execute()

                    self.logger.info(f"Recorded knowledge asset: {file_path} ({asset_type})")

                except Exception as e:
                    self.logger.warning(f"Failed to record knowledge asset {file_path}: {e}")

        except Exception as e:
            self.logger.error(f"Error recording knowledge assets: {e}")

    def run_improvement_check(self, project_id: str):
        """æ”¹å–„ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        self.logger.info(f"Checking improvement triggers for {project_id}")

        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
        if not self.check_cooldown(project_id):
            self.logger.info(f"Skipping {project_id}: in cooldown period")
            return

        # ãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯
        trigger = self.check_triggers(project_id)
        if not trigger:
            self.logger.debug(f"No triggers detected for {project_id}")
            return

        self.logger.info(f"Trigger detected for {project_id}: {trigger['trigger_type']}")

        # æ”¹å–„ææ¡ˆã‚’é›†ç´„
        run_ids = trigger['details'].get('run_ids', [])
        improvements = self.aggregate_improvements(run_ids)

        if not improvements['suggestions'] and not improvements['missing_skills']:
            self.logger.warning(f"No improvement suggestions found for {project_id}")
            return

        self.logger.info(f"Aggregated improvements: {len(improvements['suggestions'])} suggestions, "
                        f"{len(improvements['ineffective_skills'])} ineffective skills, "
                        f"{len(improvements['missing_skills'])} missing skills, "
                        f"{len(improvements['agent_suggestions'])} agent suggestions")

        # æ”¹å–„ã‚’é©ç”¨
        success = self.apply_improvement(project_id, trigger, improvements)

        if success:
            self.logger.info(f"âœ“ Improvement applied successfully for {project_id}")
        else:
            self.logger.error(f"âœ— Improvement failed for {project_id}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if not SUPABASE_AVAILABLE:
        print("âš ï¸  Supabase SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    supabase_url = os.environ.get('SUPABASE_URL')
    supabase_key = os.environ.get('SUPABASE_KEY')

    if not supabase_url or not supabase_key:
        print("âš ï¸  Supabaseèªè¨¼æƒ…å ±ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    supabase = create_client(supabase_url, supabase_key)
    engine = ImprovementEngine(supabase)

    # å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    projects_response = supabase.table('orch_projects').select('id').execute()
    projects = projects_response.data or []

    for project in projects:
        engine.run_improvement_check(project['id'])


if __name__ == '__main__':
    main()
