#!/usr/bin/env python3
"""
Improvement Engine - è‡ªå·±æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³

è©•ä¾¡çµæœã‹ã‚‰å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã€è‡ªå‹•çš„ã«æ”¹å–„ã‚’é©ç”¨ã™ã‚‹ã€‚
"""

import os
import json
import logging
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
import hashlib

try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent / '.env')
except ImportError:
    pass

try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False


class ImprovementEngine:
    """è‡ªå‹•æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, supabase: Client, logger: Optional[logging.Logger] = None):
        self.supabase = supabase
        self.logger = logger or self._setup_logging()
        self.projects_dir = Path.home() / 'projects'

        # å®‰å…¨æ€§è¨­å®š
        self.cooldown_hours = 24  # åŒã˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯24æ™‚é–“ã«1å›ã¾ã§
        self.max_improvements_per_week = 3  # åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯é€±ã«3å›ã¾ã§

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
        logger = logging.getLogger('ImprovementEngine')
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        logger.addHandler(handler)
        return logger

    def check_triggers(self, project_id: str) -> Optional[Dict[str, Any]]:
        """
        æ”¹å–„ãƒˆãƒªã‚¬ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            ãƒˆãƒªã‚¬ãƒ¼æƒ…å ±ï¼ˆæ¤œå‡ºã•ã‚Œãªã‘ã‚Œã°Noneï¼‰
            {
                'trigger_type': 'consecutive_failures' or 'low_score',
                'details': {...}
            }
        """
        # ãƒˆãƒªã‚¬ãƒ¼1: åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ãŒ3å›é€£ç¶š
        consecutive_failure_trigger = self._check_consecutive_failures(project_id)
        if consecutive_failure_trigger:
            return consecutive_failure_trigger

        # ãƒˆãƒªã‚¬ãƒ¼2: ç›´è¿‘5å®Ÿè¡Œã®å¹³å‡ã‚¹ã‚³ã‚¢ãŒ5.0æœªæº€
        low_score_trigger = self._check_low_average_score(project_id)
        if low_score_trigger:
            return low_score_trigger

        return None

    def _check_consecutive_failures(self, project_id: str) -> Optional[Dict[str, Any]]:
        """3å›é€£ç¶šã®åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ã‚’æ¤œå‡º"""
        try:
            # ç›´è¿‘10å®Ÿè¡Œã‚’å–å¾—
            response = self.supabase.table('orch_runs') \
                .select('id, status, created_at') \
                .eq('project_id', project_id) \
                .order('created_at', desc=True) \
                .limit(10) \
                .execute()

            runs = response.data or []
            if len(runs) < 3:
                return None

            # ç›´è¿‘3ã¤ãŒå¤±æ•—ã‹ãƒã‚§ãƒƒã‚¯
            recent_runs = runs[:3]
            if not all(run['status'] == 'failed' for run in recent_runs):
                return None

            # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¤±æ•—ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
            run_ids = [run['id'] for run in recent_runs]
            eval_response = self.supabase.table('orch_evaluations') \
                .select('run_id, failure_category') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = eval_response.data or []
            if len(evaluations) < 3:
                return None

            # åŒã˜ã‚«ãƒ†ã‚´ãƒªã®å¤±æ•—ãŒ3å›ç¶šã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            categories = [e['failure_category'] for e in evaluations if e['failure_category']]
            if len(categories) >= 3 and categories[0] == categories[1] == categories[2]:
                return {
                    'trigger_type': 'consecutive_failures',
                    'details': {
                        'failure_category': categories[0],
                        'run_ids': run_ids,
                        'count': 3
                    }
                }

            return None

        except Exception as e:
            self.logger.error(f"Error checking consecutive failures: {e}")
            return None

    def _check_low_average_score(self, project_id: str) -> Optional[Dict[str, Any]]:
        """ç›´è¿‘5å®Ÿè¡Œã®å¹³å‡ã‚¹ã‚³ã‚¢ãŒ5.0æœªæº€ã‚’æ¤œå‡º"""
        try:
            # ç›´è¿‘5å®Ÿè¡Œã®è©•ä¾¡ã‚’å–å¾—
            response = self.supabase.table('orch_runs') \
                .select('id') \
                .eq('project_id', project_id) \
                .order('created_at', desc=True) \
                .limit(5) \
                .execute()

            runs = response.data or []
            if len(runs) < 5:
                return None

            run_ids = [run['id'] for run in runs]
            eval_response = self.supabase.table('orch_evaluations') \
                .select('overall_score') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = eval_response.data or []
            if len(evaluations) < 5:
                return None

            scores = [e['overall_score'] for e in evaluations]
            avg_score = sum(scores) / len(scores)

            if avg_score < 5.0:
                return {
                    'trigger_type': 'low_score',
                    'details': {
                        'average_score': avg_score,
                        'run_ids': run_ids,
                        'scores': scores
                    }
                }

            return None

        except Exception as e:
            self.logger.error(f"Error checking low average score: {e}")
            return None

    def check_cooldown(self, project_id: str) -> bool:
        """
        ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            True: æ”¹å–„å¯èƒ½, False: ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­
        """
        try:
            # ç›´è¿‘ã®æ”¹å–„å±¥æ­´ã‚’å–å¾—
            cutoff_time = (datetime.now() - timedelta(hours=self.cooldown_hours)).isoformat()

            response = self.supabase.table('orch_improvement_history') \
                .select('applied_at') \
                .eq('project_id', project_id) \
                .gte('applied_at', cutoff_time) \
                .execute()

            if response.data and len(response.data) > 0:
                self.logger.info(f"Project {project_id} is in cooldown period")
                return False

            return True

        except Exception as e:
            self.logger.error(f"Error checking cooldown: {e}")
            return False

    def aggregate_improvements(self, run_ids: List[int]) -> List[str]:
        """
        è©•ä¾¡ã‹ã‚‰æ”¹å–„ææ¡ˆã‚’é›†ç´„

        Args:
            run_ids: å¯¾è±¡ã®run IDãƒªã‚¹ãƒˆ

        Returns:
            æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆ
        """
        try:
            response = self.supabase.table('orch_evaluations') \
                .select('improvement_suggestions') \
                .in_('run_id', run_ids) \
                .execute()

            evaluations = response.data or []
            all_suggestions = []

            for evaluation in evaluations:
                try:
                    suggestions = json.loads(evaluation['improvement_suggestions'])
                    all_suggestions.extend(suggestions)
                except (json.JSONDecodeError, TypeError):
                    continue

            # é‡è¤‡ã‚’é™¤å»
            unique_suggestions = list(set(all_suggestions))
            return unique_suggestions

        except Exception as e:
            self.logger.error(f"Error aggregating improvements: {e}")
            return []

    def apply_improvement(self, project_id: str, trigger: Dict[str, Any], suggestions: List[str]) -> bool:
        """
        æ”¹å–„ã‚’é©ç”¨ï¼ˆåˆ¥ãƒ–ãƒ©ãƒ³ãƒã«ï¼‰

        Args:
            project_id: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            trigger: ãƒˆãƒªã‚¬ãƒ¼æƒ…å ±
            suggestions: æ”¹å–„ææ¡ˆãƒªã‚¹ãƒˆ

        Returns:
            æˆåŠŸã—ãŸã‚‰True
        """
        try:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            project_dir_mapping = {
                'idiom': 'idiom-metaphor-analyzer',
                'orchestrator-dashboard': 'orchestrator-dashboard',
                'docflow': 'docflow',
                'tagless': 'tagless',
                'orchestrator': '../orchestrator'
            }

            dir_name = project_dir_mapping.get(project_id, project_id)
            project_dir = self.projects_dir / dir_name

            if not project_dir.exists():
                self.logger.error(f"Project directory not found: {project_dir}")
                return False

            # ãƒ–ãƒ©ãƒ³ãƒåã‚’ç”Ÿæˆ
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            branch_name = f"auto-improvement-{timestamp}"

            # æ”¹å–„å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            improvement_prompt = f"""## è‡ªå‹•æ”¹å–„ã‚¿ã‚¹ã‚¯

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}

## ãƒˆãƒªã‚¬ãƒ¼
ã‚¿ã‚¤ãƒ—: {trigger['trigger_type']}
è©³ç´°: {json.dumps(trigger['details'], indent=2)}

## æ”¹å–„ææ¡ˆ
{chr(10).join(f'{i+1}. {s}' for i, s in enumerate(suggestions))}

## æŒ‡ç¤º

ä¸Šè¨˜ã®æ”¹å–„ææ¡ˆã«åŸºã¥ã„ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ¼ãƒ‰ã€CLAUDE.mdã€ã¾ãŸã¯ã‚¹ã‚­ãƒ«ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚

é‡è¦:
- å¤‰æ›´ã¯æ…é‡ã«è¡Œã„ã€æ—¢å­˜ã®æ©Ÿèƒ½ã‚’å£Šã•ãªã„ã“ã¨
- CLAUDE.mdã«æ”¹å–„å†…å®¹ã‚’è¨˜éŒ²ã™ã‚‹ã“ã¨
- å¤‰æ›´ç†ç”±ã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨
- å®Ÿè£…å¾Œã€å¤‰æ›´å†…å®¹ã‚’ã‚µãƒãƒªãƒ¼ã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã“ã¨

å‡ºåŠ›å½¢å¼:
```changes
ãƒ•ã‚¡ã‚¤ãƒ«1: path/to/file1 - å¤‰æ›´å†…å®¹ã®èª¬æ˜
ãƒ•ã‚¡ã‚¤ãƒ«2: path/to/file2 - å¤‰æ›´å†…å®¹ã®èª¬æ˜
```
"""

            self.logger.info(f"Applying improvement to {project_id} on branch {branch_name}")

            # Gitã§æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
            subprocess.run(
                ['git', 'checkout', '-b', branch_name],
                cwd=project_dir,
                check=True,
                capture_output=True
            )

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãå‡ºã™
            temp_file = Path('/tmp') / f'improvement_{project_id}_{timestamp}.txt'
            temp_file.write_text(improvement_prompt, encoding='utf-8')

            # Claude Codeã§æ”¹å–„ã‚’å®Ÿè¡Œ
            result = subprocess.run(
                ['bash', '-c', f'cd {project_dir} && cat {temp_file} | claude --dangerously-skip-permissions --print'],
                capture_output=True,
                text=True,
                timeout=600
            )

            temp_file.unlink(missing_ok=True)

            if result.returncode != 0:
                self.logger.error(f"Improvement execution failed: {result.stderr}")
                # ãƒ–ãƒ©ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦å…ƒã«æˆ»ã™
                subprocess.run(['git', 'checkout', '-'], cwd=project_dir, capture_output=True)
                subprocess.run(['git', 'branch', '-D', branch_name], cwd=project_dir, capture_output=True)
                return False

            # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
            subprocess.run(['git', 'add', '.'], cwd=project_dir, check=True)
            commit_message = f"""Auto-improvement: {trigger['trigger_type']}

Trigger details: {json.dumps(trigger['details'])}

Improvements applied:
{chr(10).join(f'- {s}' for s in suggestions[:5])}

ğŸ¤– Auto-generated improvement
"""
            subprocess.run(
                ['git', 'commit', '-m', commit_message],
                cwd=project_dir,
                check=True,
                capture_output=True
            )

            # æ”¹å–„å±¥æ­´ã‚’è¨˜éŒ²
            self._record_improvement_history(project_id, trigger, branch_name, result.stdout)

            self.logger.info(f"Improvement applied successfully to branch: {branch_name}")
            self.logger.info(f"Review and merge manually: cd {project_dir} && git checkout {branch_name}")

            return True

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Git operation failed: {e}")
            return False
        except subprocess.TimeoutExpired:
            self.logger.error("Improvement execution timed out")
            return False
        except Exception as e:
            self.logger.error(f"Error applying improvement: {e}")
            return False

    def _record_improvement_history(self, project_id: str, trigger: Dict[str, Any], branch_name: str, output: str):
        """æ”¹å–„å±¥æ­´ã‚’è¨˜éŒ²"""
        try:
            # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º
            import re
            changes_match = re.search(r'```changes\s*\n(.*?)\n```', output, re.DOTALL)
            changes_summary = changes_match.group(1) if changes_match else "No summary provided"

            # target_filesã‚’æ§‹ç¯‰
            target_files = []
            if changes_match:
                for line in changes_match.group(1).split('\n'):
                    if ':' in line:
                        file_path = line.split(':')[0].strip()
                        target_files.append(file_path)

            self.supabase.table('orch_improvement_history').insert({
                'project_id': project_id,
                'trigger_type': trigger['trigger_type'],
                'trigger_details': json.dumps(trigger['details']),
                'target_files': json.dumps(target_files),
                'changes_summary': changes_summary,
                'before_avg_score': trigger['details'].get('average_score', 0.0)
            }).execute()

            self.logger.info(f"Improvement history recorded for {project_id}")

        except Exception as e:
            self.logger.error(f"Error recording improvement history: {e}")

    def run_improvement_check(self, project_id: str):
        """æ”¹å–„ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        self.logger.info(f"Checking improvement triggers for {project_id}")

        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
        if not self.check_cooldown(project_id):
            self.logger.info(f"Skipping {project_id}: in cooldown period")
            return

        # ãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯
        trigger = self.check_triggers(project_id)
        if not trigger:
            self.logger.debug(f"No triggers detected for {project_id}")
            return

        self.logger.info(f"Trigger detected for {project_id}: {trigger['trigger_type']}")

        # æ”¹å–„ææ¡ˆã‚’é›†ç´„
        run_ids = trigger['details'].get('run_ids', [])
        suggestions = self.aggregate_improvements(run_ids)

        if not suggestions:
            self.logger.warning(f"No improvement suggestions found for {project_id}")
            return

        self.logger.info(f"Aggregated {len(suggestions)} improvement suggestions")

        # æ”¹å–„ã‚’é©ç”¨
        success = self.apply_improvement(project_id, trigger, suggestions)

        if success:
            self.logger.info(f"âœ“ Improvement applied successfully for {project_id}")
        else:
            self.logger.error(f"âœ— Improvement failed for {project_id}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if not SUPABASE_AVAILABLE:
        print("âš ï¸  Supabase SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    supabase_url = os.environ.get('SUPABASE_URL')
    supabase_key = os.environ.get('SUPABASE_KEY')

    if not supabase_url or not supabase_key:
        print("âš ï¸  Supabaseèªè¨¼æƒ…å ±ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    supabase = create_client(supabase_url, supabase_key)
    engine = ImprovementEngine(supabase)

    # å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    projects_response = supabase.table('orch_projects').select('id').execute()
    projects = projects_response.data or []

    for project in projects:
        engine.run_improvement_check(project['id'])


if __name__ == '__main__':
    main()
