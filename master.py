#!/usr/bin/env python3
"""
Master Orchestrator - è‡ªå¾‹å‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼

è¤‡æ•°ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›£è¦–ã—ã€æŒ‡ç¤ºã‚’å—ã‘å–ã£ã¦è‡ªå¾‹çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹
"""

import os
import sys
import json
import sqlite3
import time
import logging
import signal
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# python-dotenvã§ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent / '.env')
except ImportError:
    pass

# Supabase SDK (ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False


class OrchestratorDB:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã‚¯ãƒ©ã‚¹"""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = None
        self.logger = logging.getLogger('OrchestratorDB')

    def connect(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ: {self.db_path}")
            self._initialize_schema()
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _initialize_schema(self):
        """ã‚¹ã‚­ãƒ¼ãƒã‚’åˆæœŸåŒ–"""
        schema_file = Path(self.db_path).parent / "init_schema.sql"
        if schema_file.exists():
            with open(schema_file, 'r', encoding='utf-8') as f:
                self.conn.executescript(f.read())
            self.conn.commit()
            self.logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def close(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.conn:
            self.conn.close()
            self.logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")

    def upsert_project_state(self, state: Dict[str, Any]):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã‚’æŒ¿å…¥ã¾ãŸã¯æ›´æ–°"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT OR REPLACE INTO project_states
                (project_name, last_scanned, status, current_task, last_commit,
                 uncommitted_changes, recent_errors, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                state['project_name'],
                state.get('last_scanned'),
                state.get('status', 'idle'),
                state.get('current_task'),
                state.get('last_commit'),
                state.get('uncommitted_changes', 0),
                json.dumps(state.get('recent_errors', []), ensure_ascii=False),
                datetime.now().isoformat()
            ))
            self.conn.commit()
            self.logger.debug(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°: {state['project_name']}")
        except Exception as e:
            self.logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def add_instruction(self, instruction: str) -> int:
        """æ–°ã—ã„æŒ‡ç¤ºã‚’è¿½åŠ """
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO instructions (raw_instruction, status, created_at)
                VALUES (?, ?, ?)
            ''', (instruction, 'pending', datetime.now().isoformat()))
            self.conn.commit()
            self.logger.info(f"æ–°ã—ã„æŒ‡ç¤ºã‚’è¿½åŠ : ID={cursor.lastrowid}")
            return cursor.lastrowid
        except Exception as e:
            self.logger.error(f"æŒ‡ç¤ºã®è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return -1

    def get_pending_instructions(self) -> List[Dict[str, Any]]:
        """æœªå‡¦ç†ã®æŒ‡ç¤ºã‚’å–å¾—"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT * FROM instructions WHERE status = 'pending' ORDER BY created_at ASC
        ''')
        return [dict(row) for row in cursor.fetchall()]

    def update_instruction_status(self, instruction_id: int, status: str,
                                   parsed_tasks: Optional[str] = None,
                                   result: Optional[str] = None):
        """æŒ‡ç¤ºã®çŠ¶æ…‹ã‚’æ›´æ–°"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                UPDATE instructions
                SET status = ?, parsed_tasks = ?, result = ?, processed_at = ?
                WHERE id = ?
            ''', (status, parsed_tasks, result, datetime.now().isoformat(), instruction_id))
            self.conn.commit()
            self.logger.debug(f"æŒ‡ç¤ºçŠ¶æ…‹ã‚’æ›´æ–°: ID={instruction_id}, status={status}")
        except Exception as e:
            self.logger.error(f"æŒ‡ç¤ºçŠ¶æ…‹ã®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def add_system_event(self, event_type: str, severity: str, message: str,
                        details: Optional[Dict] = None):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO system_events (event_type, severity, message, details, created_at)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                event_type,
                severity,
                message,
                json.dumps(details, ensure_ascii=False) if details else None,
                datetime.now().isoformat()
            ))
            self.conn.commit()
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã®è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    def get_project_state(self, project_name: str) -> Optional[Dict[str, Any]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã‚’å–å¾—"""
        cursor = self.conn.cursor()
        cursor.execute('SELECT * FROM project_states WHERE project_name = ?', (project_name,))
        row = cursor.fetchone()
        return dict(row) if row else None


class Orchestrator:
    """ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = {}
        self.db = None
        self.running = False
        self.logger = self._setup_logging()
        self.supabase = None
        self._initialize_supabase()

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚®ãƒ³ã‚°ã‚’è¨­å®š"""
        logger = logging.getLogger('Orchestrator')
        logger.setLevel(logging.DEBUG)

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        log_dir = Path.home() / "orchestrator" / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / f"orchestrator_{datetime.now().strftime('%Y%m%d')}.log"

        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)

        return logger

    def _initialize_supabase(self):
        """Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰"""
        if not SUPABASE_AVAILABLE:
            return

        supabase_url = os.environ.get('SUPABASE_URL')
        supabase_key = os.environ.get('SUPABASE_KEY')

        if supabase_url and supabase_key:
            try:
                self.supabase = create_client(supabase_url, supabase_key)
                self.logger.info("âœ“ Supabaseé€£æºæœ‰åŠ¹")
            except Exception as e:
                self.logger.warning(f"SupabaseåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def _save_task_to_supabase(self, task: Dict[str, Any], instruction_id: int):
        """ã‚¿ã‚¹ã‚¯ã‚’Supabaseã®orch_tasksã«ä¿å­˜"""
        if not self.supabase:
            return

        try:
            task_data = {
                'project_id': task.get('project'),
                'title': task.get('description'),
                'description': task.get('description'),
                'why': f"Instruction ID: {instruction_id}",
                'status': 'pending',
                'priority': 'normal',
                'estimated_hours': None,
                'actual_hours': None,
                'blockers': [],
                'dependencies': []
            }

            self.supabase.table('orch_tasks').insert(task_data).execute()
            self.logger.debug(f"âœ“ ã‚¿ã‚¹ã‚¯ã‚’Supabaseã«ä¿å­˜: {task.get('description')}")

        except Exception as e:
            self.logger.warning(f"Supabaseã‚¿ã‚¹ã‚¯ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            self.logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config_path}")
            self.logger.info(f"ç®¡ç†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {len(self.config['projects'])}")
        except Exception as e:
            self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def initialize(self):
        """åˆæœŸåŒ–å‡¦ç†"""
        self.logger.info("="*60)
        self.logger.info("Orchestrator åˆæœŸåŒ–é–‹å§‹")
        self.logger.info("="*60)

        # è¨­å®šèª­ã¿è¾¼ã¿
        self.load_config()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        db_path = self.config['paths']['db']
        self.db = OrchestratorDB(db_path)
        self.db.connect()

        # ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
        self.db.add_system_event('startup', 'info', 'Orchestrator started')

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã®åˆæœŸèª­ã¿è¾¼ã¿
        self._load_project_states()

        self.logger.info("åˆæœŸåŒ–å®Œäº†")

    def _load_project_states(self):
        """å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€"""
        for project in self.config['projects']:
            project_name = project['name']
            project_path = Path(project['path'])
            state_file = project_path / "PROJECT_STATE.json"

            try:
                if state_file.exists():
                    with open(state_file, 'r', encoding='utf-8') as f:
                        state_data = json.load(f)

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    project_state = {
                        'project_name': project_name,
                        'last_scanned': state_data.get('scan_timestamp'),
                        'status': 'idle',
                        'last_commit': state_data.get('git_status', {}).get('latest_commit', {}).get('hash'),
                        'uncommitted_changes': len(state_data.get('git_status', {}).get('uncommitted_changes', [])),
                        'recent_errors': state_data.get('recent_logs', {}).get('recent_errors', [])
                    }
                    self.db.upsert_project_state(project_state)
                    self.logger.info(f"âœ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿: {project_name}")
                else:
                    self.logger.warning(f"âš ï¸  PROJECT_STATE.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {project_name}")
            except Exception as e:
                self.logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({project_name}): {e}")

    def check_inbox(self):
        """inboxã«æ–°ã—ã„æŒ‡ç¤ºãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯"""
        inbox_path = Path(self.config['paths']['inbox'])

        for file_path in inbox_path.glob('*.json'):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                instruction = data.get('instruction')
                if instruction:
                    self.logger.info(f"ğŸ“¨ æ–°ã—ã„æŒ‡ç¤ºã‚’å—ä¿¡: {file_path.name}")
                    self.logger.info(f"   å†…å®¹: {instruction}")

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    instruction_id = self.db.add_instruction(instruction)

                    # å‡¦ç†
                    self.process_instruction(instruction_id, instruction)

                    # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
                    processed_dir = inbox_path / "processed"
                    processed_dir.mkdir(exist_ok=True)
                    file_path.rename(processed_dir / file_path.name)

            except Exception as e:
                self.logger.error(f"æŒ‡ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({file_path.name}): {e}")

    def process_instruction(self, instruction_id: int, instruction: str):
        """æŒ‡ç¤ºã‚’å‡¦ç†ã—ã¦ã‚¿ã‚¹ã‚¯ã«åˆ†è§£"""
        self.logger.info(f"ğŸ“‹ æŒ‡ç¤ºã‚’å‡¦ç†ä¸­: ID={instruction_id}")

        try:
            # æŒ‡ç¤ºã‚’è§£æï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            parsed_tasks = self._parse_instruction(instruction)

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            self.db.update_instruction_status(
                instruction_id,
                'processing',
                json.dumps(parsed_tasks, ensure_ascii=False)
            )

            # Supabaseã«ã‚¿ã‚¹ã‚¯ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
            for task in parsed_tasks:
                self._save_task_to_supabase(task, instruction_id)

            # çµæœã‚’outboxã«å‡ºåŠ›
            self._output_result(instruction_id, instruction, parsed_tasks)

            # å®Œäº†
            self.db.update_instruction_status(
                instruction_id,
                'done',
                result='Tasks parsed and output to outbox'
            )

            self.logger.info(f"âœ… æŒ‡ç¤ºå‡¦ç†å®Œäº†: ID={instruction_id}")

        except Exception as e:
            self.logger.error(f"æŒ‡ç¤ºå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            self.db.update_instruction_status(
                instruction_id,
                'failed',
                result=f"Error: {str(e)}"
            )

    def _parse_instruction(self, instruction: str) -> List[Dict[str, Any]]:
        """æŒ‡ç¤ºã‚’è§£æã—ã¦ã‚¿ã‚¹ã‚¯ã«åˆ†è§£"""
        tasks = []
        instruction_lower = instruction.lower()

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã®æŠ½å‡º
        project_names = [p['name'] for p in self.config['projects']]
        target_project = None

        for project_name in project_names:
            if project_name in instruction_lower:
                target_project = project_name
                break

        # ã‚¿ã‚¹ã‚¯ã®æ¨æ¸¬
        if 'çŠ¶æ…‹' in instruction or 'status' in instruction_lower:
            tasks.append({
                'type': 'check_status',
                'project': target_project,
                'description': f'{target_project}ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ…‹ã‚’ç¢ºèª'
            })

        if 'ã‚³ãƒŸãƒƒãƒˆ' in instruction or 'commit' in instruction_lower:
            tasks.append({
                'type': 'git_commit',
                'project': target_project,
                'description': f'{target_project}ã®å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ'
            })

        if 'todo' in instruction_lower:
            tasks.append({
                'type': 'organize_todos',
                'project': target_project,
                'description': f'{target_project}ã®TODOã‚’æ•´ç†'
            })

        if not tasks:
            tasks.append({
                'type': 'unknown',
                'project': target_project,
                'description': 'æŒ‡ç¤ºã®å†…å®¹ãŒä¸æ˜ã§ã™'
            })

        return tasks

    def _output_result(self, instruction_id: int, instruction: str,
                      parsed_tasks: List[Dict[str, Any]]):
        """å‡¦ç†çµæœã‚’outboxã«å‡ºåŠ›"""
        outbox_path = Path(self.config['paths']['outbox'])
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = outbox_path / f"result_{instruction_id}_{timestamp}.json"

        result = {
            'instruction_id': instruction_id,
            'instruction': instruction,
            'parsed_tasks': parsed_tasks,
            'processed_at': datetime.now().isoformat(),
            'status': 'Tasks identified but not executed yet (state management only)'
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ“¤ çµæœã‚’å‡ºåŠ›: {output_file.name}")

    def scan_projects(self):
        """å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ…‹ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        for project in self.config['projects']:
            if not project.get('auto_scan', True):
                continue

            project_name = project['name']
            project_path = Path(project['path'])

            # scan_project.pyãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’å®Ÿè¡Œ
            scan_script = project_path / "scan_project.py"
            if scan_script.exists():
                try:
                    import subprocess
                    result = subprocess.run(
                        ['python3', str(scan_script)],
                        cwd=project_path,
                        capture_output=True,
                        text=True,
                        timeout=30
                    )

                    if result.returncode == 0:
                        self.logger.debug(f"âœ“ ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {project_name}")
                        # çŠ¶æ…‹ã‚’å†èª­ã¿è¾¼ã¿
                        self._load_project_states()
                    else:
                        self.logger.warning(f"ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼ ({project_name}): {result.stderr}")

                except Exception as e:
                    self.logger.error(f"ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({project_name}): {e}")

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.running = True
        scan_interval = self.config['settings']['scan_interval_seconds']
        inbox_interval = self.config['settings'].get('inbox_check_interval', 10)

        last_scan = 0
        last_inbox_check = 0

        self.logger.info("="*60)
        self.logger.info("Orchestrator ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—é–‹å§‹")
        self.logger.info(f"ã‚¹ã‚­ãƒ£ãƒ³é–“éš”: {scan_interval}ç§’")
        self.logger.info(f"inboxç¢ºèªé–“éš”: {inbox_interval}ç§’")
        self.logger.info("="*60)

        try:
            while self.running:
                current_time = time.time()

                # inboxç¢ºèª
                if current_time - last_inbox_check >= inbox_interval:
                    self.check_inbox()
                    last_inbox_check = current_time

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³
                if current_time - last_scan >= scan_interval:
                    self.logger.info("ğŸ” å®šæœŸã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œä¸­...")
                    self.scan_projects()
                    last_scan = current_time

                # æœªå‡¦ç†ã®æŒ‡ç¤ºã‚’å‡¦ç†
                pending = self.db.get_pending_instructions()
                for instruction in pending:
                    self.process_instruction(
                        instruction['id'],
                        instruction['raw_instruction']
                    )

                # çŸ­ã„ã‚¹ãƒªãƒ¼ãƒ—
                time.sleep(1)

        except KeyboardInterrupt:
            self.logger.info("ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        except Exception as e:
            self.logger.error(f"ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.shutdown()

    def shutdown(self):
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å‡¦ç†"""
        self.logger.info("="*60)
        self.logger.info("Orchestrator ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ä¸­...")
        self.logger.info("="*60)

        if self.db:
            self.db.add_system_event('shutdown', 'info', 'Orchestrator stopped')
            self.db.close()

        self.running = False
        self.logger.info("ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    orchestrator_dir = Path.home() / "orchestrator"
    config_path = orchestrator_dir / "config.json"

    if not config_path.exists():
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        sys.exit(1)

    orchestrator = Orchestrator(str(config_path))

    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
    def signal_handler(sig, frame):
        print("\nå‰²ã‚Šè¾¼ã¿ã‚·ã‚°ãƒŠãƒ«ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        orchestrator.running = False

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        orchestrator.initialize()
        orchestrator.run()
    except Exception as e:
        print(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
